server:
  port: 9004

spring:
  kafka:
    bootstrap-servers: localhost:9092 #指定Kafka Broker地址，多个用逗号分隔
    #Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答，1-leader应答，all-所有leader 和flower 应答。
      retries: 3 #发送失败时，重复发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer #消息的key的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer #消息的value的序列化
      #事务消息配置
      #transaction-id-prefix: demo. #事务编号前缀，使用事务消息，需要设置acks=all
      # 配置批量发送消息的三个条件，满足其一就可执行。 如果不使用批量发送，将下边三个条件注释。
    #      batch-size: 16348 #每次批量发送消息的最大数量
#      buffer-memory: 33554432 #每次批量发送消息的最大内存
#      properties:
#        linger:
#          ms: 30000 #批处理延迟时间上限，配置成了 30 秒，主要为了演示之用。这里配置30 * 1000 ms，过后，不管消息是否到达batch-size数量，或者消息大小是否到达buffer-memory，都直接发送。
    #Kafka Consumer 配置项
    consumer:
      #设置消费者分组最初的消费进度为earliest
      #earliest 当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费。
      #latest 当分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据。
      #none 当该topic下所有分区中存在未提交的offset时，抛出异常。
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      #配置batch poll 批量拉取
#      fetch-max-wait: 10000 # poll一次拉取的阻塞的最大时长，单位：毫秒。这里指的是阻塞拉取需要满足至少 fetch-min-size 大小的消息
#      fetch-min-size: 10 # poll一次消息拉取的最小数据量。单位：字节
#      max-poll-records: 100 # poll一次消息拉取的最大数量
      properties:
        spring:
          json:
            trusted:
              packages: com.cc.kafka.message  #JsonDeserializer 在反序列化消息时，考虑到安全性，只反序列化成信任的 Message 类
      # 使用spirng-kafka 消费进度提交机制
      enable-auto-commit: false
        # 事务消息 隔离级别
    #        isolation:
#          level: read_committed # 读取已提交的消息
    #Kafka Consumer Listener 监听器配置
    listener:
#      type: batch # 监听器类型。默认single,只监听单挑消息。这里配置 batch,监听多条消息，批量消费。
      missing-topics-fatal: false #消费监听接口监听的topic不存在时，默认会报错。所以通过设置为false,解决报错。
      ack-mode: manual #手动提交消费进度

resource:
  logger:
    level: info

logging:
  level:
    org:
      springframework:
        kafka: ERROR # spring-kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别
      apache:
        kafka: ERROR # kafka INFO 日志太多了，所以我们限制只打印 ERROR 级别

